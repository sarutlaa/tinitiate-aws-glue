
# AWS Glue

> Sravya Arutla




## Introduction

AWS Glue is a Serverless data integration i.e., fully managed Extract, Transform, and Load (ETL) service that makes it easy to prepare and process data for analytics and machine learning. It automates the discovery, cataloging, cleaning, enriching, and moving of data between various data stores enabling more focus on analyzing the data rather than managing the infrastructure.

Below are the listed Key AWS Glue Components.


## AWS Glue Components

### Glue Data Catalog


The Glue Data Catalog is a central metadata repository that stores information about your data assets, regardless of where they are located. It acts as a unified metadata store for all your data sources and targets, enabling seamless data discovery, ETL, and query execution across your datasets.


### Database

Within the AWS Glue Data Catalog, a database is a logical grouping of tables. It helps organize your data catalog and makes it easier to manage access and permissions for different datasets.

### Data store, data source, and data target

* Data Store: A repository for storing data. In AWS Glue, data stores can be Amazon S3 buckets, Amazon RDS databases, Amazon DynamoDB tables, and more.
* Data Source: The location from which your ETL job sources its data. It can be any data store accessible by AWS Glue.
* Data Target: The destination where your ETL job writes the transformed data. Like the data source, it can be any data store that AWS Glue supports.

### Table
In the context of AWS Glue, a table is a metadata definition that represents your data. Tables in AWS Glue are similar to tables in a relational database, and they store metadata about your data such as column names, data types, and other properties.

### Crawler and Classifier

* Crawler: A component of AWS Glue that scans various data stores to automatically discover and infer schemas. It categorizes data formats and suggests schemas and transformations, populating the Glue Data Catalog with table definitions.

* Classifier: Determines the schema of your data. When a crawler runs, it invokes classifiers to infer the format and schema of your data. Classifiers can recognize various file formats and data types, including JSON, CSV, and Parquet.

### AWS Glue Studio

AWS Glue Studio is an integrated development environment (IDE) that simplifies the creation, management, and execution of ETL jobs. It offers a visual interface for designing ETL workflows, enabling both novice and experienced users to easily define their data transformation logic.

### Job

In AWS Glue, a job is a business logic that automates the ETL process. It involves extracting data from a source, transforming this data according to specified rules, and loading it into a target destination.

### Script

Scripts are written in PySpark (Python for Apache Spark) and generated by AWS Glue to carry out the transformations defined in your ETL jobs. These scripts can be customized and edited as needed to meet specific data transformation requirements.

### Development endpoint

A development endpoint is an environment that you can use to develop and test your ETL scripts interactively. It provides a serverless Apache Spark environment for exploring and experimenting with your data transformation logic before deploying it as a job.

### Trigger

Triggers in AWS Glue are conditions or schedules that automatically start your ETL jobs. They can be set to run based on a schedule, in response to an event, or on-demand, allowing for flexible and automated execution of your data workflows.


Each of these components plays a crucial role in the AWS Glue service, working together to provide a comprehensive and scalable solution for data integration and ETL processes across a wide range of data sources and formats.
